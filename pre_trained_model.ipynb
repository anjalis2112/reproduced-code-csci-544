{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61788a73-cb2c-4a25-b0fb-6574be1a62a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from evaluator import Evaluator\n",
    "from transformers import AutoTokenizer\n",
    "from models.EmpathicSimilarityModel import EmpathicSimilarityModel\n",
    "from dataset import EmpathicStoriesDataset\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c9e2936-11d3-463a-a86b-b0183d8c29e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.multiprocessing as mp\n",
    "\n",
    "mp.set_sharing_strategy('file_system')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28f0350d-eb4d-47fa-997b-f2dcd7f63690",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2017424-a895-4282-8614-5c3fb6717aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e936b39-c0cd-4baa-9308-afba758d60b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_pairs = pd.read_csv('data/PAIRS (test).csv')\n",
    "df_test_stories = pd.read_csv('data/STORIES (test).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53e76f83-ba5e-4c11-b194-822427b22138",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/mili/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/mili/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/mili/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "evaluator = Evaluator(device=device, df_test_pairs=df_test_pairs, df_test_stories=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa983cb2-68fa-4f76-986b-a7918175b179",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = EmpathicStoriesDataset(task=\"similarity\", data_pairs=df_test_pairs, data_stories=None, labels=[])\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1129543-c4e7-4a44-b527-590d85ad1480",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions = []\n",
    "all_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20981c9a-fe23-4a3f-b97d-13e864c85b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `SpearmanCorrcoef` will save all targets and predictions in the buffer. For large datasets, this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = \"models/EmpathicStoriesBART.ckpt\"\n",
    "checkpoint = torch.load(model_checkpoint, map_location=torch.device('cpu'))  # Load on CPU\n",
    "model_state_dict = checkpoint['state_dict'] \n",
    "model = EmpathicSimilarityModel(checkpoint)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eee55c9d-0ad3-4e67-b3a8-846ce2f36a27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmpathicSimilarityModel(\n",
       "  (lm_model): BartForConditionalGeneration(\n",
       "    (model): BartModel(\n",
       "      (shared): Embedding(50265, 768, padding_idx=1)\n",
       "      (encoder): BartEncoder(\n",
       "        (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
       "        (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
       "        (layers): ModuleList(\n",
       "          (0-5): 6 x BartEncoderLayer(\n",
       "            (self_attn): BartSdpaAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): BartDecoder(\n",
       "        (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
       "        (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
       "        (layers): ModuleList(\n",
       "          (0-5): 6 x BartDecoderLayer(\n",
       "            (self_attn): BartSdpaAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (activation_fn): GELUActivation()\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): BartSdpaAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n",
       "  )\n",
       "  (model): BartModel(\n",
       "    (shared): Embedding(50265, 768, padding_idx=1)\n",
       "    (encoder): BartEncoder(\n",
       "      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x BartEncoderLayer(\n",
       "          (self_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): BartDecoder(\n",
       "      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x BartDecoderLayer(\n",
       "          (self_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (f1_score): BinaryF1Score()\n",
       "  (spearman): SpearmanCorrCoef()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device=device) \n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a613abd-a746-4e94-9610-e921b7cbbdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in test_dataloader:\n",
    "    stories_a, stories_b, labels = batch\n",
    "    combined_stories = []\n",
    "    for story_a, story_b in zip(stories_a, stories_b):\n",
    "        combined_stories.append((story_a, story_b))\n",
    "    with torch.no_grad():\n",
    "        predictions = model(combined_stories)\n",
    "    all_predictions.append(predictions)\n",
    "    all_labels.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a063113-04d5-46ef-b01e-8441ee87761b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n",
      "8\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "print(len(all_predictions[0][0]))\n",
    "print(len(all_predictions[0]))\n",
    "print(len(all_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2aac388f-b32b-45ec-9c88-912aa7cbf250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "print(len(all_labels))\n",
    "print(len(all_labels[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c203e7-706f-4498-b211-64c5330337f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_predictions = np.mean(all_predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07631b8c-c163-48e8-9cac-309a4773a938",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator(device=device, df_test_pairs=df_test_pairs, df_test_stories=None)\n",
    "pearson_corr = evaluator.get_pearson(all_predictions, all_labels)\n",
    "# Print the results\n",
    "print(\"Pearson Correlation Coefficient:\", pearson_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c865d4-29f4-47fa-8b9e-86992b0b0658",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e49f0d6-a697-4422-82ee-c4344bd0787f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_predictions[0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f272df-020c-40b0-95ef-f8a6e9fcf1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
